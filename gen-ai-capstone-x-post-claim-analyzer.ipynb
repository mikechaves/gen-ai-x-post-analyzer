{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Gen AI Capstone: X Post Claim Analyzer\n\n**Author(s):** Michael Chaves\n**Date:** April 2025\n\n## Introduction: The Challenge of Information on X\n\nThe rapid flow of information on platforms like X (formerly Twitter) presents a challenge: how can users quickly assess the potential reliability of factual claims within posts? While definitive \"truth detection\" by AI is complex and arguably impossible, Generative AI offers tools to *assist* users in this process.\n\nThis Capstone project, developed for the **5-Day Gen AI Intensive Course with Google**, demonstrates a prototype **Gen AI Assistant** designed to:\n1.  **Extract** potentially verifiable factual claims from sample X posts using Structured Output and Few-Shot Prompting.\n2.  **Attempt Verification** by querying a simulated knowledge base using Function Calling.\n3.  **Summarize** the findings concisely, ensuring the summary is Grounded in the verification results.\n\n**Disclaimer:** This tool is an educational prototype using simulated data and knowledge sources. It is **NOT** a definitive fact-checker or truth detector but rather demonstrates specific Gen AI capabilities.\n\n**Gen AI Capabilities Showcased:** This project demonstrates the application of the following key capabilities:\n* **Structured Output:** Extracting information in a predefined JSON format.\n* **Few-Shot Prompting:** Guiding model behavior with examples for improved accuracy.\n* **Function Calling:** Enabling the LLM to interact with simulated external tools/knowledge.\n* **Document Understanding & Grounding:** Processing input text and ensuring generated summaries are based strictly on provided evidence.","metadata":{}},{"cell_type":"markdown","source":"## 1. Setup and Configuration\n\nThis section handles the initial setup, including importing necessary libraries, configuring the connection to the Generative AI model, and initializing the model instance.\n\n### 1.1 Libraries\n\nWe import standard libraries like `os` and `json`, the `google-generativeai` library for interacting with the Gemini API, and `kaggle_secrets` for securely accessing the API key.\n\n### 1.2 API Key Configuration\n\nAccess to the Gemini API requires an API key. **Important:** Store your API key securely using Kaggle Secrets (Add-ons -> Secrets). Add a secret named `GOOGLE_API_KEY` (or update the code if you used a different name) containing your key value.\n\nThe following code retrieves the key from Kaggle Secrets and configures the `google-generativeai` library. It includes error handling in case the secret is not found. **Never expose your API key directly in the notebook code.**\n\n### 1.3 Model Initialization\n\nWe initialize the Gemini model we'll be using for various tasks (claim extraction, function calling decisions, summarization). We are starting with `gemini-1.5-flash-latest` for its balance of speed and capability. The model instance `model` will be used in subsequent steps.","metadata":{}},{"cell_type":"code","source":"# --- 1. Setup ---\nprint(\"--- 1. Setup ---\")\n\n# Install necessary libraries (only needed once per session)\n# !pip install -q google-generativeai\n\nimport google.generativeai as genai\nimport os\nimport json # For handling JSON data\n# import pandas as pd # Optional: if you prefer DataFrames for handling data\n\n# --- Configure API Key ---\ntry:\n    from kaggle_secrets import UserSecretsClient\n    user_secrets = UserSecretsClient()\n    GOOGLE_API_KEY = user_secrets.get_secret(\"GOOGLE_API_KEY\")\n    genai.configure(api_key=GOOGLE_API_KEY)\n    print(\"Gemini API Key configured successfully.\")\nexcept Exception as e:\n    print(f\"Error configuring Gemini API Key: {e}\")\n    print(\"Please ensure 'GOOGLE_API_KEY' is set in Kaggle Secrets.\")\n    # Handle the error appropriately - maybe stop execution or use a dummy mode\n    GOOGLE_API_KEY = None # Set to None if key retrieval fails\n\n# --- Initialize the Generative Model ---\n# Let's start with gemini-1.5-flash, which is fast and capable\n# If you have access and need JSON mode enforcement, gemini-1.5-pro might be better\nmodel_name = \"gemini-1.5-flash-latest\"\n# If using 1.5 Pro for guaranteed JSON:\n# model_name = \"gemini-1.5-pro-latest\"\n# generation_config_json = genai.types.GenerationConfig(response_mime_type=\"application/json\")\n\nif GOOGLE_API_KEY:\n    model = genai.GenerativeModel(model_name)\n    # If using 1.5 Pro for guaranteed JSON:\n    # model = genai.GenerativeModel(model_name, generation_config=generation_config_json)\n    print(f\"Initialized model: {model_name}\")\nelse:\n    model = None\n    print(\"Model not initialized due to missing API key.\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-10T04:20:21.117291Z","iopub.execute_input":"2025-04-10T04:20:21.117981Z","iopub.status.idle":"2025-04-10T04:20:21.252203Z","shell.execute_reply.started":"2025-04-10T04:20:21.117958Z","shell.execute_reply":"2025-04-10T04:20:21.251106Z"}},"outputs":[{"name":"stdout","text":"--- 1. Setup ---\nGemini API Key configured successfully.\nInitialized model: gemini-1.5-flash-latest\n","output_type":"stream"}],"execution_count":40},{"cell_type":"markdown","source":"## 2. Sample Data\n\nDue to the offline requirements for Kaggle submissions and the complexities of live API access, this notebook operates on a small, predefined list of sample \"X Posts\". This static data allows us to demonstrate the workflow consistently.\n\nThe sample data includes a mix of posts containing:\n* Clear factual claims (some potentially verifiable by our mini-KB).\n* Opinions or subjective statements.\n* Questions.\n\nThe code below defines and displays these sample posts.","metadata":{}},{"cell_type":"code","source":"# --- 2. Sample Data ---\nprint(\"\\n--- 2. Sample Data ---\")\n\n# Using a list of strings for simplicity. You could use dicts or a DataFrame.\nsample_tweets = [\n    # 1. Factual, likely verifiable by simple KB\n    \"Just read that Python 3.10 was released on October 4, 2021. Time flies! #Python\",\n    # 2. Factual, less likely verifiable by simple KB\n    \"Amazing turnout at the local park cleanup event today! Over 50 volunteers showed up. #Community\",\n    # 3. Opinion\n    \"This new AI model is the best thing since sliced bread! So impressed. #AI #Tech\",\n    # 4. Question\n    \"Does anyone know if Kaggle was founded in 2010 or 2011? #Kaggle\",\n    # 5. Factual, but incorrect info (relative to a potential KB)\n    \"Paris is the capital of Spain, right? Planning my trip! #Travel\",\n    # 6. Factual, potentially verifiable\n    \"France's national day, Bastille Day, is celebrated on 14 July. #France #History\" ,\n    # 7. No clear factual claim\n    \"Feeling excited about the upcoming weekend! #TGIF\"\n]\n\nprint(f\"Loaded {len(sample_tweets)} sample tweets.\")\n# Displaying first few tweets\nfor i, tweet in enumerate(sample_tweets[:3]):\n    print(f\"Tweet {i+1}: {tweet}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T04:20:21.254107Z","iopub.execute_input":"2025-04-10T04:20:21.254433Z","iopub.status.idle":"2025-04-10T04:20:21.261053Z","shell.execute_reply.started":"2025-04-10T04:20:21.254407Z","shell.execute_reply":"2025-04-10T04:20:21.259972Z"}},"outputs":[{"name":"stdout","text":"\n--- 2. Sample Data ---\nLoaded 7 sample tweets.\nTweet 1: Just read that Python 3.10 was released on October 4, 2021. Time flies! #Python\nTweet 2: Amazing turnout at the local park cleanup event today! Over 50 volunteers showed up. #Community\nTweet 3: This new AI model is the best thing since sliced bread! So impressed. #AI #Tech\n","output_type":"stream"}],"execution_count":41},{"cell_type":"markdown","source":"## 3. Extracting Factual Claims\n\nThe first core step is to identify potentially verifiable factual claims within each post, separating them from opinions, questions, or general commentary. We instruct the LLM to return these claims in a structured format for easier processing in later steps.\n\n### 3.1 Defining the Output Structure\n\nFor reliable processing, we require the LLM to output extracted claims in a specific JSON format. The desired structure includes a list of claims, where each claim has the `claim_text` (the verbatim claim) and suggested `keywords` (useful for potential searching).\n\n```json\n{\n  \"claims\": [\n    {\n      \"claim_text\": \"Specific verifiable fact stated in the post.\",\n      \"keywords\": [\"entity1\", \"entity2\", \"event\"]\n    }\n  ]\n}","metadata":{}},{"cell_type":"code","source":"# --- 3. Extract Factual Claims ---\n# Note: Ensure Step 1 (Setup) has been run successfully and 'model' is initialized.\n# Note: Ensure Step 2 (Sample Data) has been run and 'sample_tweets' exists.\n# Note: Ensure 'json' library is imported from Step 1.\nprint(\"\\n--- 3. Extract Factual Claims ---\")\n\n# --- Claim Extraction Prompt (with Few-Shot Examples) ---\ndef create_extraction_prompt(tweet_text):\n    # Define 2-3 clear examples\n    example_1_input = \"Just read that Python 3.10 was released on October 4, 2021. Time flies! #Python\"\n    example_1_output = \"\"\"\n{\n  \"claims\": [\n    {\n      \"claim_text\": \"Python 3.10 was released on October 4, 2021\",\n      \"keywords\": [\"Python 3.10\", \"release date\", \"October 4 2021\"]\n    }\n  ]\n}\n\"\"\"\n\n    example_2_input = \"This new AI model is the best thing since sliced bread! So impressed. #AI #Tech\"\n    example_2_output = \"\"\"\n{\n  \"claims\": []\n}\n\"\"\"\n\n    example_3_input = \"France's national day, Bastille Day, is celebrated on 14 July. #France\"\n    example_3_output = \"\"\"\n{\n  \"claims\": [\n    {\n      \"claim_text\": \"France's national day, Bastille Day, is celebrated on 14 July\",\n      \"keywords\": [\"France\", \"Bastille Day\", \"14 July\"]\n    }\n  ]\n}\n\"\"\"\n\n    # Construct the prompt with clear instructions and examples\n    prompt = f\"\"\"\nAnalyze the following post carefully. Your task is to identify sentences or phrases that state objective, verifiable factual claims. Ignore opinions, questions, subjective statements, predictions, and general commentary.\n\nFormat your output strictly as a JSON object containing a single key \"claims\". The value associated with \"claims\" must be a list of JSON objects. Each object in the list represents one factual claim found and must have two keys:\n1.  \"claim_text\": The exact verbatim factual claim extracted from the post.\n2.  \"keywords\": A list of 1-3 key entities, concepts, or terms from the claim text that would be useful for searching or verification.\n\nIf no verifiable factual claims are found in the post, return a JSON object with an empty list: {{\"claims\": []}}\n\nEnsure your entire output is only the valid JSON object, starting with {{ and ending with }}.\n\nHere are some examples:        <-- **** LOOK FOR THIS LINE ****\n\nPost:\n\\\"\\\"\\\"\n{example_2_input}\n\\\"\\\"\\\"\nJSON Output:\n```json\n{example_2_output.strip()}\n\nPost:\n\\\"\\\"\\\"\n{example_2_input}\n\\\"\\\"\\\"\nJSON Output:\n```json\n{example_2_output.strip()}\n\nPost:\n\\\"\\\"\\\"\n{example_3_input}\n\\\"\\\"\\\"\nJSON Output:\n```json\n{example_3_output.strip()}\n\n```                        <-- **** EXAMPLES END HERE ****\n\nNow, analyze the following post:\n\nPost:\n\\\"\\\"\\\"\n{tweet_text}\n\\\"\\\"\\\"\n\nJSON Output:\n\"\"\"\n    # Consider removing the final ```json ... ``` markers if using guaranteed JSON mode\n    # (e.g., with Gemini 1.5 Pro) as it might expect pure JSON. Test what works best.\n    return prompt\n\n# --- Claim Extraction Function ---\n# (Includes error handling and validation)\ndef extract_claims(tweet_text, model):\n    if not model:\n        print(\"Model not available.\")\n        return {\"claims\": [], \"error\": \"Model not initialized\"} # Return error structure\n\n    prompt = create_extraction_prompt(tweet_text)\n    try:\n        # Generate content using the model\n        # Adjust generation config if needed (e.g., temperature, JSON mode)\n        response = model.generate_content(prompt)\n\n        # Attempt to parse the response as JSON\n        # Clean potential markdown formatting ```json ... ``` first\n        cleaned_text = response.text.strip().lstrip('```json').rstrip('```').strip()\n        extracted_data = json.loads(cleaned_text)\n\n        # Basic validation of the parsed structure\n        if \"claims\" not in extracted_data or not isinstance(extracted_data[\"claims\"], list):\n             print(f\"Warning: Unexpected JSON structure from LLM for post: {tweet_text[:50]}...\")\n             return {\"claims\": [], \"error\": \"Invalid JSON structure received\"}\n\n        # Further validate structure of items within 'claims' list if needed\n        for item in extracted_data[\"claims\"]:\n             if not isinstance(item, dict) or \"claim_text\" not in item or \"keywords\" not in item:\n                  print(f\"Warning: Invalid item structure within claims for post: {tweet_text[:50]}...\")\n                  return {\"claims\": [], \"error\": \"Invalid item structure in claims list\"}\n             if not isinstance(item[\"keywords\"], list):\n                   print(f\"Warning: Keywords not a list for post: {tweet_text[:50]}...\")\n                   return {\"claims\": [], \"error\": \"Keywords field is not a list\"}\n\n        return extracted_data\n\n    except json.JSONDecodeError as e:\n        print(f\"Error decoding JSON from LLM response for post: {tweet_text[:50]}...\")\n        print(f\"LLM Raw Text: '{response.text}'\") # Print raw text for debugging\n        return {\"claims\": [], \"error\": f\"JSON Decode Error: {e}\"}\n    except Exception as e:\n        # Catch other potential errors during API call or processing\n        print(f\"An error occurred during claim extraction for post: {tweet_text[:50]}...\")\n        print(f\"Error: {e}\")\n        # Attempt to access response parts or feedback for more details if available\n        try:\n             # Check candidate feedback first if available\n             if hasattr(response, 'prompt_feedback') and response.prompt_feedback:\n                 print(f\"LLM Response Feedback: {response.prompt_feedback}\")\n             # Check parts if feedback isn't informative or error happened differently\n             elif hasattr(response, 'parts'):\n                 print(f\"LLM Response Parts: {response.parts}\")\n        except Exception:\n             pass # Ignore errors during error reporting\n        return {\"claims\": [], \"error\": f\"General Error: {e}\"}\n\n\n# --- Process Sample Tweets ---\n# Make sure 'sample_tweets' list exists from Step 2\nif 'sample_tweets' not in globals():\n     print(\"Error: sample_tweets list not found. Please run Step 2 first.\")\nelif 'model' not in globals() or model is None:\n     print(\"Error: 'model' is not initialized. Please run Step 1 successfully.\")\nelse:\n    # Initialize/reset the results list before processing\n    extracted_claims_results = []\n    print(\"\\nProcessing posts to extract claims...\")\n    for tweet in sample_tweets:\n        result = extract_claims(tweet, model) # Assumes 'model' is initialized\n        extracted_claims_results.append({\"original_tweet\": tweet, \"extraction_result\": result})\n\n    print(\"Finished extracting claims.\")\n\n    # --- Display Extraction Results ---\n    print(\"\\n--- Extracted Claims Results ---\")\n    if not 'extracted_claims_results' in globals() or not extracted_claims_results:\n         print(\"Claim extraction did not run or produced no results variable.\")\n    else:\n        for item in extracted_claims_results:\n            print(f\"Original Post: {item['original_tweet']}\")\n            result = item['extraction_result']\n            # Check for error key *and* ensure it has a value\n            if \"error\" in result and result['error']:\n                print(f\"  Error: {result['error']}\")\n            # Check for claims key *and* ensure it's not empty\n            elif not result.get('claims'): # Use .get for safer access, catches missing key or empty list/None\n                print(\"  No factual claims identified.\")\n            else:\n                claims_list = result.get('claims', []) # Get claims list safely\n                if not claims_list: # Double check if list is empty after .get\n                     print(\"  No factual claims identified.\")\n                else:\n                    for i, claim_info in enumerate(claims_list):\n                        # Use .get for claim_text and keywords for robustness\n                        print(f\"  Claim {i+1}: {claim_info.get('claim_text', 'N/A')}\")\n                        print(f\"    Keywords: {claim_info.get('keywords', 'N/A')}\")\n            print(\"-\" * 20)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T04:20:21.262365Z","iopub.execute_input":"2025-04-10T04:20:21.262844Z","iopub.status.idle":"2025-04-10T04:20:25.217924Z","shell.execute_reply.started":"2025-04-10T04:20:21.262798Z","shell.execute_reply":"2025-04-10T04:20:25.216900Z"}},"outputs":[{"name":"stdout","text":"\n--- 3. Extract Factual Claims ---\n\nProcessing posts to extract claims...\nFinished extracting claims.\n\n--- Extracted Claims Results ---\nOriginal Post: Just read that Python 3.10 was released on October 4, 2021. Time flies! #Python\n  Claim 1: Python 3.10 was released on October 4, 2021\n    Keywords: ['Python 3.10', 'release date', 'October 4, 2021']\n--------------------\nOriginal Post: Amazing turnout at the local park cleanup event today! Over 50 volunteers showed up. #Community\n  Claim 1: Over 50 volunteers showed up\n    Keywords: ['volunteers', 'park cleanup', 'number']\n--------------------\nOriginal Post: This new AI model is the best thing since sliced bread! So impressed. #AI #Tech\n  No factual claims identified.\n--------------------\nOriginal Post: Does anyone know if Kaggle was founded in 2010 or 2011? #Kaggle\n  No factual claims identified.\n--------------------\nOriginal Post: Paris is the capital of Spain, right? Planning my trip! #Travel\n  No factual claims identified.\n--------------------\nOriginal Post: France's national day, Bastille Day, is celebrated on 14 July. #France #History\n  Claim 1: France's national day, Bastille Day, is celebrated on 14 July\n    Keywords: ['France', 'Bastille Day', 'July 14']\n--------------------\nOriginal Post: Feeling excited about the upcoming weekend! #TGIF\n  No factual claims identified.\n--------------------\n","output_type":"stream"}],"execution_count":42},{"cell_type":"markdown","source":"## 4. Simulating Evidence Search via Function Calling\n\nOnce factual claims are extracted, we attempt to verify them. In a real-world scenario, this might involve searching the web or specific databases. For this offline Capstone project, we **simulate** this process using **Function Calling**.\n\nWe define a simple knowledge base and a Python function to search it. We then make the LLM aware of this function (as a \"tool\") and instruct it to call the function *only* when appropriate to verify a claim based on its keywords.\n\n### 4.1 Simulated Knowledge Base (KB)\n\nA small Python dictionary (`mini_kb`) acts as our \"trusted source\". It contains a few predefined facts relevant to our sample posts. This allows us to demonstrate the *mechanism* of function calling and verification, even if the knowledge is limited.","metadata":{}},{"cell_type":"code","source":"# --- 4. Simulate Evidence Search (Function Calling) ---\nprint(\"\\n--- 4. Simulate Evidence Search (Function Calling) ---\")\n\n# --- 4.1. Define Simulated Knowledge Base ---\n# A simple dictionary acting as our 'reliable source' for demo purposes.\n# Keys/values should relate to potential claims in your sample_tweets.\nmini_kb = {\n    \"Python 3.10 release date\": \"October 4, 2021\",\n    \"Kaggle founding year\": 2010,\n    \"Capital of France\": \"Paris\",\n    \"Bastille Day date\": \"14 July\",\n    # Add 1-2 more simple facts if relevant to your sample tweets\n}\nprint(\"Mini Knowledge Base (KB) defined:\")\nprint(mini_kb)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T04:20:25.219097Z","iopub.execute_input":"2025-04-10T04:20:25.219426Z","iopub.status.idle":"2025-04-10T04:20:25.225344Z","shell.execute_reply.started":"2025-04-10T04:20:25.219399Z","shell.execute_reply":"2025-04-10T04:20:25.224315Z"}},"outputs":[{"name":"stdout","text":"\n--- 4. Simulate Evidence Search (Function Calling) ---\nMini Knowledge Base (KB) defined:\n{'Python 3.10 release date': 'October 4, 2021', 'Kaggle founding year': 2010, 'Capital of France': 'Paris', 'Bastille Day date': '14 July'}\n","output_type":"stream"}],"execution_count":43},{"cell_type":"markdown","source":"### 4.2 KB Search Function (`search_knowledge_base`)\n\nThis standard Python function simulates querying the KB. It accepts `query_keywords` (provided by the LLM) and performs simple string matching against the `mini_kb`. It returns a string indicating whether confirming information was found, if a contradiction was detected (based on simple hardcoded rules for this demo), or if no relevant information was available in the KB.","metadata":{}},{"cell_type":"code","source":"# --- 4.2. Define Python Function to Search KB ---\n# This function will be callable by the LLM via Function Calling.\ndef search_knowledge_base(query_keywords: list) -> str:\n    \"\"\"\n    Searches the mini_kb for information related to the query_keywords.\n    Returns a string indicating what was found, contradicted, or not found.\n    \"\"\"\n    print(f\"  -> KB Search Function called with keywords: {query_keywords}\")\n    found_info = []\n    if not query_keywords:\n        return \"No keywords provided for search.\"\n\n    query_str = \" \".join(query_keywords).lower() # Combine keywords for simple matching\n\n    for key, value in mini_kb.items():\n        key_lower = key.lower()\n        value_str_lower = str(value).lower() # Convert value to string for searching\n\n        # Simple check if combined keywords appear in key or value\n        # More sophisticated matching could be done here (e.g., check individual keywords)\n        if query_str in key_lower or query_str in value_str_lower:\n            found_info.append(f\"Possible match found in KB: '{key}: {value}'\")\n        # Check if a keyword matches a key directly\n        elif any(keyword.lower() in key_lower for keyword in query_keywords):\n             found_info.append(f\"Possible match found in KB: '{key}: {value}'\")\n\n    if found_info:\n        return \" | \".join(found_info) # Return all potential matches\n    else:\n        # Check for potential contradictions (simple example)\n        if \"paris\" in query_str and \"spain\" in query_str:\n            return f\"KB Contradiction: KB lists Capital of France as '{mini_kb.get('Capital of France', 'N/A')}'.\"\n        elif \"kaggle\" in query_str and \"2011\" in query_str:\n             return f\"KB Contradiction: KB lists Kaggle founding year as {mini_kb.get('Kaggle founding year', 'N/A')}.\"\n        else:\n             return \"No relevant information found in Mini KB for the given keywords.\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T04:20:25.227836Z","iopub.execute_input":"2025-04-10T04:20:25.228118Z","iopub.status.idle":"2025-04-10T04:20:25.248487Z","shell.execute_reply.started":"2025-04-10T04:20:25.228099Z","shell.execute_reply":"2025-04-10T04:20:25.247412Z"}},"outputs":[],"execution_count":44},{"cell_type":"markdown","source":"### 4.3 Defining the Tool for the LLM\n\nTo enable **Function Calling**, we must describe our Python function (`search_knowledge_base`) to the LLM using a specific schema (OpenAPI-like). This `FunctionDeclaration` tells the LLM the tool's name, purpose, and the expected parameters (`query_keywords`).","metadata":{}},{"cell_type":"code","source":"# --- 4.3. Define the Function Declaration for the LLM Tool ---\n# Describe the function so the LLM knows how and when to use it.\n# CORRECTED version using dictionary-based schema (OpenAPI style)\n\ntry:\n    search_tool = genai.types.FunctionDeclaration(\n        name=\"search_knowledge_base\",\n        description=\"Searches a small knowledge base for facts related to given keywords (like dates, places, events, entities) to help verify a claim. Use keywords extracted from the claim.\",\n        # Define parameters using a dictionary matching OpenAPI schema\n        parameters={\n            'type': 'object', # Use lowercase string \"object\" for the top level\n            'properties': {\n                'query_keywords': { # Define the parameter name\n                    'type': 'array',  # Use lowercase string \"array\"\n                    'description': \"List of 1-3 key entities, concepts, or terms from the claim to search for.\",\n                    'items': {        # Describe the items within the array\n                        'type': 'string' # Use lowercase string \"string\"\n                    }\n                }\n            },\n            'required': [\"query_keywords\"] # List required parameters\n        }\n    )\n    print(\"Function Declaration 'search_tool' created successfully.\")\n\nexcept Exception as e:\n    print(f\"Error creating Function Declaration: {e}\")\n    # Handle error appropriately, maybe set search_tool to None\n    search_tool = None","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T04:20:25.249842Z","iopub.execute_input":"2025-04-10T04:20:25.250158Z","iopub.status.idle":"2025-04-10T04:20:25.278085Z","shell.execute_reply.started":"2025-04-10T04:20:25.250132Z","shell.execute_reply":"2025-04-10T04:20:25.276943Z"}},"outputs":[{"name":"stdout","text":"Function Declaration 'search_tool' created successfully.\n","output_type":"stream"}],"execution_count":45},{"cell_type":"markdown","source":"### 4.4 Implementation: Calling the Function\n\nThe core logic involves:\n1.  Re-initializing the Gemini model with the `tools` parameter set to our `search_tool` declaration.\n2.  Iterating through each `claim` extracted earlier.\n3.  Creating a new prompt asking the LLM to *decide* whether using the `search_knowledge_base` tool is appropriate for verifying the current claim, based on its text and keywords.\n4.  Calling the LLM with this prompt and the tool definition.\n5.  Checking the LLM's response:\n    * If the response contains a `function_call` part for `search_knowledge_base`: We parse the arguments (keywords) provided by the LLM and execute our *local* Python `search_knowledge_base` function with them.\n    * If the response contains only text: The LLM decided not to call the function (e.g., deemed it irrelevant), and we record its textual response.\n6.  Storing the result of this verification attempt (either the output from our Python function or the LLM's textual refusal).\n\n### 4.5 Verification Attempt Results\n\nThe code cell below performs this verification loop and displays the outcome for each claim.","metadata":{}},{"cell_type":"code","source":"# --- 4.4. Process Claims and Attempt Verification ---\nverification_results = []\nprint(\"\\nAttempting verification for extracted claims using Function Calling...\")\n\nif not model:\n    print(\"Skipping verification as model not initialized.\")\nelse:\n    # Re-initialize model with the tool (important!)\n    # Note: If using flash, it might sometimes struggle with complex function calling. Pro might be more reliable.\n    model_with_tool = genai.GenerativeModel(model_name, tools=[search_tool])\n    print(f\"Re-initialized model '{model_name}' with search tool.\")\n\n    for item in extracted_claims_results:\n        original_tweet = item[\"original_tweet\"]\n        claims = item[\"extraction_result\"].get(\"claims\", [])\n        tweet_verifications = []\n\n        if not claims or \"error\" in item[\"extraction_result\"]:\n            # Skip if no claims were extracted or if there was an extraction error\n            verification_results.append({\n                \"original_tweet\": original_tweet,\n                \"verifications\": tweet_verifications # Empty list\n            })\n            continue\n\n        print(f\"\\nVerifying claims for tweet: {original_tweet[:60]}...\")\n        for claim_info in claims:\n            claim_text = claim_info.get(\"claim_text\", \"N/A\")\n            keywords = claim_info.get(\"keywords\", [])\n\n            if claim_text == \"N/A\" or not keywords:\n                 tweet_verifications.append({\n                    \"claim\": claim_text,\n                    \"keywords\": keywords,\n                    \"verification_attempted\": False,\n                    \"raw_llm_response\": None,\n                    \"kb_search_result\": \"Skipped (missing claim or keywords).\"\n                 })\n                 continue\n\n            # Prompt for the LLM asking it to use the tool if appropriate\n            verification_prompt = f\"\"\"\n            Consider the following factual claim extracted from a social media post:\n            Claim: \"{claim_text}\"\n            Keywords: {keywords}\n\n            Use the available 'search_knowledge_base' tool ONLY IF it seems likely to help verify this specific claim based on the keywords. If the tool is not relevant for verifying this claim, respond directly stating that verification wasn't possible with available tools. Do not make up information.\n            \"\"\"\n\n            try:\n                # Send prompt and tool definition to the model\n                response = model_with_tool.generate_content(verification_prompt)\n                response_part = response.candidates[0].content.parts[0]\n                kb_search_result = \"Verification not attempted by LLM.\" # Default\n\n                # Check if the model decided to call the function\n                if response_part.function_call.name == \"search_knowledge_base\":\n                    function_call = response_part.function_call\n                    args = function_call.args\n\n                    # Execute the *local* Python function\n                    function_response_text = search_knowledge_base(\n                        query_keywords=args.get(\"query_keywords\", [])\n                    )\n                    kb_search_result = function_response_text # Store the result\n\n                elif response_part.text:\n                    # If the LLM responded directly without calling the function\n                     kb_search_result = f\"LLM Response (No Tool Call): {response_part.text}\"\n\n\n                tweet_verifications.append({\n                    \"claim\": claim_text,\n                    \"keywords\": keywords,\n                    \"verification_attempted\": response_part.function_call.name == \"search_knowledge_base\",\n                    \"raw_llm_response_part\": str(response_part), # Store for debugging\n                    \"kb_search_result\": kb_search_result\n                 })\n\n            except Exception as e:\n                 print(f\"  Error during verification for claim '{claim_text[:50]}...': {e}\")\n                 # Log response parts if possible\n                 try:\n                     print(f\"  LLM Response Parts on Error: {response.candidates[0].content.parts}\")\n                 except: pass\n                 tweet_verifications.append({\n                    \"claim\": claim_text,\n                    \"keywords\": keywords,\n                    \"verification_attempted\": False,\n                    \"raw_llm_response\": None,\n                    \"kb_search_result\": f\"Error during verification: {e}\"\n                 })\n\n        verification_results.append({\n            \"original_tweet\": original_tweet,\n            \"verifications\": tweet_verifications\n        })\n\nprint(\"\\nFinished attempting verification.\")\n\n# --- Display Verification Results ---\nprint(\"\\n--- Verification Attempt Results ---\")\nfor item in verification_results:\n    print(f\"Original Tweet: {item['original_tweet']}\")\n    if not item['verifications']:\n        print(\"  No claims were processed for verification.\")\n    else:\n        for i, verification in enumerate(item['verifications']):\n            print(f\"  Claim {i+1}: {verification['claim']}\")\n            print(f\"    Keywords: {verification['keywords']}\")\n            print(f\"    Verification Attempted: {verification['verification_attempted']}\")\n            print(f\"    KB Search Result/LLM Response: {verification['kb_search_result']}\")\n            # print(f\"    Raw LLM Part: {verification['raw_llm_response_part']}\") # Optional: for debugging\n    print(\"-\" * 20)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T04:20:25.279320Z","iopub.execute_input":"2025-04-10T04:20:25.279693Z","iopub.status.idle":"2025-04-10T04:20:27.205724Z","shell.execute_reply.started":"2025-04-10T04:20:25.279664Z","shell.execute_reply":"2025-04-10T04:20:27.204631Z"}},"outputs":[{"name":"stdout","text":"\nAttempting verification for extracted claims using Function Calling...\nRe-initialized model 'gemini-1.5-flash-latest' with search tool.\n\nVerifying claims for tweet: Just read that Python 3.10 was released on October 4, 2021. ...\n  -> KB Search Function called with keywords: ['Python 3.10', 'release date', 'October 4, 2021']\n\nVerifying claims for tweet: Amazing turnout at the local park cleanup event today! Over ...\n\nVerifying claims for tweet: France's national day, Bastille Day, is celebrated on 14 Jul...\n  -> KB Search Function called with keywords: ['France', 'Bastille Day', 'July 14']\n\nFinished attempting verification.\n\n--- Verification Attempt Results ---\nOriginal Tweet: Just read that Python 3.10 was released on October 4, 2021. Time flies! #Python\n  Claim 1: Python 3.10 was released on October 4, 2021\n    Keywords: ['Python 3.10', 'release date', 'October 4, 2021']\n    Verification Attempted: True\n    KB Search Result/LLM Response: Possible match found in KB: 'Python 3.10 release date: October 4, 2021'\n--------------------\nOriginal Tweet: Amazing turnout at the local park cleanup event today! Over 50 volunteers showed up. #Community\n  Claim 1: Over 50 volunteers showed up\n    Keywords: ['volunteers', 'park cleanup', 'number']\n    Verification Attempted: False\n    KB Search Result/LLM Response: LLM Response (No Tool Call): The available tool `search_knowledge_base` is unlikely to be helpful in verifying the claim \"Over 50 volunteers showed up\" because the keywords provided do not contain a specific number or quantifiable information related to the number of volunteers.  The keyword 'number' is too generic.  Verification wasn't possible with available tools.\n\n--------------------\nOriginal Tweet: This new AI model is the best thing since sliced bread! So impressed. #AI #Tech\n  No claims were processed for verification.\n--------------------\nOriginal Tweet: Does anyone know if Kaggle was founded in 2010 or 2011? #Kaggle\n  No claims were processed for verification.\n--------------------\nOriginal Tweet: Paris is the capital of Spain, right? Planning my trip! #Travel\n  No claims were processed for verification.\n--------------------\nOriginal Tweet: France's national day, Bastille Day, is celebrated on 14 July. #France #History\n  Claim 1: France's national day, Bastille Day, is celebrated on 14 July\n    Keywords: ['France', 'Bastille Day', 'July 14']\n    Verification Attempted: True\n    KB Search Result/LLM Response: Possible match found in KB: 'Capital of France: Paris' | Possible match found in KB: 'Bastille Day date: 14 July'\n--------------------\nOriginal Tweet: Feeling excited about the upcoming weekend! #TGIF\n  No claims were processed for verification.\n--------------------\n","output_type":"stream"}],"execution_count":46},{"cell_type":"markdown","source":"## 5. Summarizing Verification Findings\n\nTo present the results clearly, we use the LLM one last time to generate a concise summary sentence based on the outcome of the simulated verification attempt.\n\nThis step utilizes the LLM's **Document Understanding** to process the claim and the verification result, and relies on **Grounding** to ensure the summary accurately reflects *only* the information provided by the simulated KB search, preventing hallucination.\n\n### 5.1 Prompt Design for Summarization\n\nThe prompt instructs the LLM to:\n* Analyze the original claim and the text result from the KB search step (`kb_search_result`).\n* Generate a single sentence stating whether the claim appears \"confirmed\", \"contradicted\", or \"unverified\" *by the available knowledge base*.\n* Crucially, base this summary *strictly* on the provided `kb_search_result`.\n\n### 5.2 Implementation: `summarize_findings` Function\n\nThe `summarize_findings` Python function takes the claim text, the KB search result string, and the model, constructs the summary prompt, calls the LLM, and returns the generated summary sentence.","metadata":{}},{"cell_type":"code","source":"# --- 5. Summarize Findings ---\nprint(\"\\n--- 5. Summarize Findings ---\")\n\ndef create_summary_prompt(claim_text, kb_search_result):\n    prompt = f\"\"\"\n    Based *only* on the provided 'KB Search Result' below, write a concise, single-sentence summary stating whether the claim appears confirmed, contradicted, or remains unverified by the available knowledge base.\n\n    - If the KB result indicates confirmation or provides matching info, state it's 'confirmed by the knowledge base'.\n    - If the KB result indicates a contradiction, state it's 'contradicted by the knowledge base'.\n    - If the KB result indicates 'No relevant information found', 'Verification not attempted', or an LLM text response instead of a KB result, state it's 'unverified by the available knowledge base'.\n    - Do not add any information not present in the KB Search Result.\n\n    Claim: \"{claim_text}\"\n    KB Search Result: \"{kb_search_result}\"\n\n    Concise Summary:\n    \"\"\"\n    return prompt\n\ndef summarize_findings(claim_text, kb_search_result, model):\n    if not model:\n        return \"Summary skipped (model not available).\"\n    if \"Error during verification\" in kb_search_result: # Handle previous errors\n         return \"Summary skipped due to verification error.\"\n\n    prompt = create_summary_prompt(claim_text, kb_search_result)\n    try:\n        response = model.generate_content(prompt)\n        # Add basic check for safety ratings if needed\n        # if response.prompt_feedback.block_reason:\n        #    return f\"Summary generation blocked: {response.prompt_feedback.block_reason}\"\n        return response.text.strip()\n    except Exception as e:\n        print(f\"  Error during summary generation for claim '{claim_text[:50]}...': {e}\")\n        return f\"Error generating summary: {e}\"\n\nprint(\"Summarization function defined.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T04:20:27.206917Z","iopub.execute_input":"2025-04-10T04:20:27.208047Z","iopub.status.idle":"2025-04-10T04:20:27.215209Z","shell.execute_reply.started":"2025-04-10T04:20:27.208010Z","shell.execute_reply":"2025-04-10T04:20:27.214084Z"}},"outputs":[{"name":"stdout","text":"\n--- 5. Summarize Findings ---\nSummarization function defined.\n","output_type":"stream"}],"execution_count":47},{"cell_type":"markdown","source":"### 5.3 Final Results Display\n\nThe final code cell integrates all previous steps. It iterates through the verification results, calls the `summarize_findings` function for each claim, and presents a consolidated view: Original Post, Extracted Claim, KB Search Result, and Final Summary Sentence.","metadata":{}},{"cell_type":"code","source":"# --- Display Final Results (Combining Extraction, Verification, and Summary) ---\nprint(\"\\n--- Final Processed Results ---\")\n\nfinal_results_display = [] # Store structured results\n\n# Make sure you have 'verification_results' from the end of step 4\nif not 'verification_results' in globals():\n     print(\"Error: verification_results not found. Please ensure step 4 ran correctly.\")\nelse:\n    for item in verification_results:\n        original_tweet = item['original_tweet']\n        verifications = item['verifications']\n        print(f\"Original Post: {original_tweet}\")\n\n        processed_verifications = []\n        if not verifications:\n            print(\"  No claims processed for verification.\")\n        else:\n            for i, verification in enumerate(verifications):\n                claim_text = verification['claim']\n                kb_result = verification['kb_search_result']\n\n                # Call the new summary function\n                summary_sentence = summarize_findings(claim_text, kb_result, model) # Use the base model is fine\n\n                print(f\"  Claim {i+1}: {claim_text}\")\n                # print(f\"    Keywords: {verification['keywords']}\") # Optional to keep\n                # print(f\"    Verification Attempted: {verification['verification_attempted']}\") # Optional\n                print(f\"    KB Search Result: {kb_result}\")\n                print(f\"    Summary: {summary_sentence}\")\n\n                # Store for potential later use\n                processed_verifications.append({\n                     \"claim\": claim_text,\n                     \"kb_search_result\": kb_result,\n                     \"summary\": summary_sentence\n                })\n        final_results_display.append({\n             \"original_post\": original_tweet,\n             \"processed_claims\": processed_verifications\n        })\n        print(\"-\" * 30) # Increase separator length","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T04:20:27.216312Z","iopub.execute_input":"2025-04-10T04:20:27.216619Z","iopub.status.idle":"2025-04-10T04:20:28.229976Z","shell.execute_reply.started":"2025-04-10T04:20:27.216593Z","shell.execute_reply":"2025-04-10T04:20:28.228984Z"}},"outputs":[{"name":"stdout","text":"\n--- Final Processed Results ---\nOriginal Post: Just read that Python 3.10 was released on October 4, 2021. Time flies! #Python\n  Claim 1: Python 3.10 was released on October 4, 2021\n    KB Search Result: Possible match found in KB: 'Python 3.10 release date: October 4, 2021'\n    Summary: Confirmed by the knowledge base.\n------------------------------\nOriginal Post: Amazing turnout at the local park cleanup event today! Over 50 volunteers showed up. #Community\n  Claim 1: Over 50 volunteers showed up\n    KB Search Result: LLM Response (No Tool Call): The available tool `search_knowledge_base` is unlikely to be helpful in verifying the claim \"Over 50 volunteers showed up\" because the keywords provided do not contain a specific number or quantifiable information related to the number of volunteers.  The keyword 'number' is too generic.  Verification wasn't possible with available tools.\n\n    Summary: Unverified by the available knowledge base.\n------------------------------\nOriginal Post: This new AI model is the best thing since sliced bread! So impressed. #AI #Tech\n  No claims processed for verification.\n------------------------------\nOriginal Post: Does anyone know if Kaggle was founded in 2010 or 2011? #Kaggle\n  No claims processed for verification.\n------------------------------\nOriginal Post: Paris is the capital of Spain, right? Planning my trip! #Travel\n  No claims processed for verification.\n------------------------------\nOriginal Post: France's national day, Bastille Day, is celebrated on 14 July. #France #History\n  Claim 1: France's national day, Bastille Day, is celebrated on 14 July\n    KB Search Result: Possible match found in KB: 'Capital of France: Paris' | Possible match found in KB: 'Bastille Day date: 14 July'\n    Summary: Confirmed by the knowledge base.\n------------------------------\nOriginal Post: Feeling excited about the upcoming weekend! #TGIF\n  No claims processed for verification.\n------------------------------\n","output_type":"stream"}],"execution_count":48},{"cell_type":"markdown","source":"## 6. Conclusion & Project Summary\n\n### 6.1 Project Recap\n\nThis notebook demonstrated a prototype Gen AI assistant designed to analyze factual claims within sample X posts (formerly Tweets). The workflow involved:\n1.  Extracting potential factual claims using an LLM guided by **Few-Shot Prompting** and **Structured Output** (JSON).\n2.  Attempting to verify these claims against a *simulated* knowledge base using **Function Calling**.\n3.  Generating a concise summary of the verification findings, emphasizing **Grounding** the summary based *only* on the simulated evidence.\n\nThis project serves as a proof-of-concept for how Gen AI tools can be combined to create assistants for navigating and analyzing information encountered on social media platforms.\n\n### 6.2 Gen AI Capabilities Demonstrated\n\nThis Capstone Project successfully demonstrated the application of **four (4)** key capabilities learned during the Gen AI Intensive Course:\n\n1.  **Structured Output:** The LLM was instructed to return extracted claims in a specific JSON format, ensuring the output could be reliably parsed and used programmatically in subsequent steps.\n2.  **Few-Shot Prompting:** Examples of desired input-output behavior were included directly in the prompt for claim extraction. This helped guide the LLM to better distinguish factual claims from opinions/questions and adhere to the required JSON structure.\n3.  **Function Calling:** A Python function simulating a knowledge base search was defined as a \"tool\". The LLM was empowered to decide when to call this function with appropriate arguments (keywords) based on the claim text, demonstrating interaction with external (simulated) systems.\n4.  **Document Understanding & Grounding:** The LLM processed the original post, extracted claims, and later generated summaries based on verification results. The summarization step specifically required the model to *ground* its output solely on the provided evidence string, preventing hallucination or the introduction of outside information.\n\n\n### 6.3 Limitations\n\nIt is crucial to acknowledge the limitations of this prototype:\n\n* **Static & Limited Data:** The analysis was performed on a small, predefined list of sample posts, not a live or comprehensive feed.\n* **Simulated Verification:** The \"knowledge base\" was extremely limited and predefined. The evidence search was entirely simulated and did not query external databases or the internet.\n* **Not a Truth Detector:** This system **does not determine truth**. It only checks claims against its tiny, simulated knowledge base. The results (\"confirmed\", \"contradicted\", \"unverified\") are strictly relative to this KB.\n* **LLM Reliability:** The entire workflow relies on the LLM's ability to accurately follow complex instructions (parsing text, identifying facts, formatting JSON, deciding when to call functions, grounding summaries). LLMs can make errors, misunderstand context, or exhibit biases.\n* **Basic Logic:** Claim extraction, keyword generation, and KB search logic are simplified for this demonstration.\n\n### 6.4 Future Work\n\nThis prototype could be extended in several ways:\n\n* **RAG Implementation:** Replace the simple KB dictionary with a proper **Retrieval-Augmented Generation** system, using **Embeddings** and **Vector Search** against a larger corpus of trusted documents.\n* **Real APIs (with caution):** Carefully integrate calls to external APIs (e.g., web search, specific knowledge bases) via Function Calling, managing API keys and usage limits.\n* **Improved Claim/Keyword Logic:** Enhance the sophistication of claim extraction and keyword generation.\n* **Gen AI Evaluation:** Implement automated checks (**Gen AI Evaluation**) to assess the quality of extracted claims or summaries against predefined criteria or human labels.\n* **User Interface:** Build a simple UI (e.g., Gradio/Streamlit) for easier interaction.","metadata":{}}]}